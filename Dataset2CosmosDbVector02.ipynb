{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauld\\git\\RAGCosmosDBReRank\\.venv\\Lib\\site-packages\\beir\\datasets\\data_loader.py:8: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "100%|██████████| 5233329/5233329 [00:17<00:00, 299733.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load beir dataset\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "data_path = \"datasets/hotpotqa\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 5233329\n"
     ]
    }
   ],
   "source": [
    "print(f'Corpus size: {len(corpus)}')\n",
    "# Take the first n items from the corpus dictionary, which is not part of the qrels_select\n",
    "n = 500\n",
    "corpus_sample = dict(list(corpus.items())[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container with id 'hotpotqase' created\n"
     ]
    }
   ],
   "source": [
    "from azure.cosmos import CosmosClient, PartitionKey, exceptions\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Cosmos client\n",
    "connection_string = os.getenv('COSMOSDB_CONN_STR') \n",
    "client = CosmosClient.from_connection_string(connection_string)\n",
    "\n",
    "# Define the database and container\n",
    "database_name = os.getenv('COSMOSDB_DB_NAME') \n",
    "container_name = os.getenv('COSMOSDB_CONTAINER_NAME') \n",
    "database = client.get_database_client(database_name)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.CRITICAL)  # set urllib3 logging level to CRITICAL\n",
    "logging.getLogger(\"azure\").setLevel(logging.CRITICAL)  # set urllib3 logging level to CRITICAL\n",
    "\n",
    "# Define indexing policy and vector embedding policy if needed\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [ \n",
    "        { \n",
    "            \"path\": \"/vectorized_text\", \n",
    "            \"dataType\": \"float32\", \n",
    "            \"distanceFunction\": \"euclidean\", \n",
    "            \"dimensions\":  1536\n",
    "        }\n",
    "    ] \n",
    "}\n",
    "\n",
    "indexing_policy = {\n",
    "    \"indexingMode\": \"consistent\",\n",
    "    \"automatic\": True,\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/vectorized_text/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"fullTextIndexes\": [],\n",
    "    \"vectorIndexes\": [\n",
    "        {\n",
    "        \"path\": \"/vectorized_text\",\n",
    "        \"type\": \"diskANN\",\n",
    "        \"quantizationByteSize\": 128,\n",
    "        \"IndexingSearchListSize\": 100\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create container if not exists\n",
    "try:\n",
    "    container = database.create_container_if_not_exists(\n",
    "        id=container_name,\n",
    "        partition_key=PartitionKey(path='/id'),\n",
    "        indexing_policy=indexing_policy,\n",
    "        vector_embedding_policy=vector_embedding_policy\n",
    "    )\n",
    "    print(f'Container with id \\'{container_name}\\' created')\n",
    "except exceptions.CosmosHttpResponseError as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.cosmos.exceptions import CosmosHttpResponseError\n",
    "\n",
    "async def insert_documents_to_cosmosdb(connection_string: str, database_name: str, container_name: str, documents: list):\n",
    "    \"\"\"\n",
    "    Insert a list of JSON documents into Cosmos DB asynchronously.\n",
    "\n",
    "    :param connection_string: Cosmos DB connection string for authentication.\n",
    "    :param database_name: Name of the Cosmos DB database.\n",
    "    :param container_name: Name of the Cosmos DB container.\n",
    "    :param documents: List of JSON documents to insert.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a Cosmos DB client\n",
    "        async with CosmosClient.from_connection_string(connection_string) as client:\n",
    "            # Get the database and container\n",
    "            database = client.get_database_client(database_name)\n",
    "            container = database.get_container_client(container_name)\n",
    "\n",
    "            # Insert documents asynchronously\n",
    "            tasks = []\n",
    "            for doc in documents:\n",
    "                tasks.append(container.upsert_item(doc))  # Use upsert to insert or update\n",
    "\n",
    "            # Wait for all tasks to complete\n",
    "            await asyncio.gather(*tasks)\n",
    "            print(f\"Successfully inserted {len(documents)} documents into Cosmos DB.\")\n",
    "\n",
    "    except CosmosHttpResponseError as e:\n",
    "        print(f\"An error occurred: {e.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus to vectorize: 5233329\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many file descriptors in select()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen runpy>:198\u001b[39m, in \u001b[36m_run_module_as_main\u001b[39m\u001b[34m(mod_name, alter_argv)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen runpy>:88\u001b[39m, in \u001b[36m_run_code\u001b[39m\u001b[34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauld\\git\\RAGCosmosDBReRank\\.venv\\Lib\\site-packages\\ipykernel_launcher.py:18\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m sys.path[\u001b[32m0\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipykernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch_new_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauld\\git\\RAGCosmosDBReRank\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py:1075\u001b[39m, in \u001b[36mApplication.launch_instance\u001b[39m\u001b[34m(cls, argv, **kwargs)\u001b[39m\n\u001b[32m   1073\u001b[39m app = \u001b[38;5;28mcls\u001b[39m.instance(**kwargs)\n\u001b[32m   1074\u001b[39m app.initialize(argv)\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauld\\git\\RAGCosmosDBReRank\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py:739\u001b[39m, in \u001b[36mIPKernelApp.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    738\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m    741\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pauld\\git\\RAGCosmosDBReRank\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py:205\u001b[39m, in \u001b[36mBaseAsyncIOLoop.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43masyncio_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py:678\u001b[39m, in \u001b[36mBaseEventLoop.run_forever\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;28mself\u001b[39m._run_forever_setup()\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m    680\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py:1995\u001b[39m, in \u001b[36mBaseEventLoop._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1992\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m   1993\u001b[39m         timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1995\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m   1997\u001b[39m \u001b[38;5;66;03m# Needed to break cycles when an exception occurs.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:314\u001b[39m, in \u001b[36mSelectSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    312\u001b[39m ready = []\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     r, w, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:305\u001b[39m, in \u001b[36mSelectSelector._select\u001b[39m\u001b[34m(self, r, w, _, timeout)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     r, w, x = \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w + x, []\n",
      "\u001b[31mValueError\u001b[39m: too many file descriptors in select()"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "api_key = os.getenv('AOAI_API_KEY')\n",
    "azure_endpoint = os.getenv('AOAI_ENDPOINT')\n",
    "\n",
    "aclient = AsyncAzureOpenAI(api_key=api_key,\n",
    "api_version=\"2024-12-01-preview\",\n",
    "azure_endpoint=azure_endpoint)\n",
    "\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.CRITICAL)  # set urllib3 logging level to CRITICAL\n",
    "logging.getLogger(\"openai\").setLevel(logging.CRITICAL)  # set urllib3 logging level to CRITICAL\n",
    "logging.getLogger(\"httpx\").setLevel(logging.CRITICAL)  # set urllib3 logging level to CRITICAL\n",
    "logging.getLogger(\"azure.cosmos\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"azure\").setLevel(logging.CRITICAL)\n",
    "\n",
    "model_name = \"text-embedding-3-small\"\n",
    "\n",
    "# Semaphore to limit concurrency\n",
    "semaphore = asyncio.Semaphore(500)  # Adjust the limit as needed\n",
    "\n",
    "async def vectorize_text(text: str):\n",
    "    async with semaphore:  # Limit the number of concurrent tasks\n",
    "        response = await aclient.embeddings.create(input=text, model=model_name)\n",
    "        data = response.data\n",
    "        if data:\n",
    "            return data[0].embedding  # Ensure embedding is JSON-serializable\n",
    "        return []\n",
    "\n",
    "import time\n",
    "# Wait to avoid rate limiting by embedding service\n",
    "wait_time = 0.01\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Corpues to vectorize\n",
    "#corpus_to_vectorize = corpus_sample\n",
    "print(f'Length of corpus to vectorize: {len(corpus)}')\n",
    "\n",
    "# Process in batches \n",
    "batch_size = 1000\n",
    "json_array = []\n",
    "\n",
    "keys_values = list(corpus.items())\n",
    "for i in range(0, len(keys_values), batch_size):\n",
    "    batch = keys_values[i:i + batch_size]\n",
    "    tasks = [vectorize_text(f\"Tile: {value['title']}, Text: {value['text']}\") for key, value in batch]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    for (key, value), embedding in zip(batch, results):\n",
    "        if embedding:  # ...existing check logic...\n",
    "            json_array.append({\n",
    "                'id': key,\n",
    "                'text': value['text'],\n",
    "                'title': value['title'],\n",
    "                'vectorized_text': embedding\n",
    "            })\n",
    "    await insert_documents_to_cosmosdb(connection_string, database_name, container_name, json_array)\n",
    "    json_array = []\n",
    "    print(f'Batch {i // batch_size + 1} completed. Processed {len(batch)} items in {time.time() - start_time} seconds')\n",
    "\n",
    "\n",
    "print(f'All documents has been vectorized. Length of the JSON array: {len(json_array)}')\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#logging.getLogger(\"azure.cosmos\").setLevel(logging.CRITICAL)\n",
    "#logging.getLogger(\"openai\").setLevel(logging.CRITICAL)\n",
    "#logging.getLogger(\"httpcore\").setLevel(logging.CRITICAL)\n",
    "# Query to get the count of items\n",
    "query = \"SELECT VALUE COUNT(1) FROM c\"\n",
    "\n",
    "# Execute the query\n",
    "result = list(container.query_items(query=query, enable_cross_partition_query=True))\n",
    "\n",
    "# The result will be a list with a single value (the count)\n",
    "for r in result:\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
